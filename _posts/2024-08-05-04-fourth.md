---
title: Machine-Learning with structured data
excerpt: "Most used algorithms, ensemble model"
categories : 
   - machine-learning 
   - study
toc : true
author_profile: false
sidebar :
    nav : "counts"
---

# Structure data vs Unstructured data
Structure data is a data that is structured. For example data that is easy to express in a database or excel. 
Unstructured data is a data that is difficult to express for example music or picture can be a unstructured data. 

# Ensemble model
Ensemble model is used for structure data. It is an algorithm that performs best in handling structured data. This ml model algorithms train multiple models to produce better predictive results.
This model combines weak classifiers and make strong classifiers.

# Random Forrest

## Booststraps
Before learning about random forests, you should understand bootstraps. 
If you have to choose 100 from 1000 models, the bootstrap technique picks one out of 1000, puts the selected model back into the entire model, and then picks next one out of 1000, and repeats 100 times like this way.

## About random forrest
Random forests first create a bootstrap sample. After that, each node is randomly selected for some characteristics and then divided. After that, find the best division. 
Train the sample this way and average the class-specific probabilities of each tree to make the class with the highest probability a prediction.


# Extra Tree
The extra tree is a model that does not use bootstrap. This model performs random segmentation, not the best segmentation, when segmenting nodes. The extra tree ensembles many trees. This model prevents overfitting and increases the score of the verification set.


# Histogram-based gradient boosting
Histogram-based gradient boosting is the most popular machine learning model. It splits the training data into 256 integer intervals for fast and high performance

```python
from sklearn.ensemble import HistGradientBoostingClassifier
hgb = HistGradientBoostingClassifier(random_state=42)
scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))

from sklearn.inspection import permutation_importance
hgb.fit(train_input, train_target)
result = permutation_importance(hgb, train_input, train_target, n_repeats=10,
                                random_state=42, n_jobs=-1)
print(result.importances_mean)

result = permutation_importance(hgb, test_input, test_target, n_repeats=10,
                                random_state=42, n_jobs=-1)
print(result.importances_mean)

hgb.score(test_input, test_target)
```
This is a python code of histogram-base gradient boosting model. We can check this model's accuracy is 86%.
